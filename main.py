"""
LLM-Based Battery Arbitrage Agent with Reflexion
ä¸»ç¨‹åºå…¥å£ - è¿è¡Œå®éªŒå¾ªç¯å¹¶å¯¹æ¯”ä¸åŒ Agent çš„æ€§èƒ½

Usage:
    uv run python main.py
    uv run python main.py --days 7
    uv run python main.py --agents rule reflexion
"""
import os
import argparse
from typing import Dict, List
from dotenv import load_dotenv

from src.env import BatteryEnv
from src.agents import RuleAgent, SimpleLLMAgent, ReflexionAgent, BaseAgent
from src.utils import (
    load_market_data,
    plot_cumulative_profits,
    plot_daily_profits,
    plot_soc_profile,
    plot_action_distribution,
    print_experiment_summary,
    create_results_dataframe,
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def run_single_agent(
    agent: BaseAgent,
    env: BatteryEnv,
    num_days: int,
    verbose: bool = True
) -> Dict:
    """
    è¿è¡Œå•ä¸ª Agent çš„å®éªŒ
    
    Args:
        agent: Agent å®ä¾‹
        env: ç¯å¢ƒå®ä¾‹
        num_days: è¿è¡Œå¤©æ•°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        åŒ…å«ç»“æœæŒ‡æ ‡çš„å­—å…¸
    """
    # é‡ç½®
    agent.reset()
    obs = env.reset()
    
    hourly_profits = []
    daily_profits = []
    all_history = []
    
    for day in range(num_days):
        daily_buffer = []
        daily_profit = 0
        
        for hour in range(24):
            if obs is None:
                break
            
            # Agent å†³ç­–
            action = agent.decide(obs)
            
            # ç¯å¢ƒæ‰§è¡Œ
            next_obs, reward, done, info = env.step(action)
            
            # è®°å½•
            hourly_profits.append(reward)
            daily_profit += reward
            daily_buffer.append(info)
            all_history.append(info)
            
            # å¦‚æœæ˜¯ ReflexionAgentï¼Œè®°å½•äº¤æ˜“
            if hasattr(agent, 'record_transaction'):
                agent.record_transaction(info)
            
            obs = next_obs
            
            if done:
                break
        
        # æ¯æ—¥ç»“æŸå¤„ç†
        daily_profits.append(daily_profit)
        
        # åæ€ï¼ˆå¦‚æœ Agent æ”¯æŒï¼‰
        reflection = agent.end_of_day(daily_buffer)
        
        if verbose:
            print(f"  Day {day + 1}: Profit ${daily_profit:.4f}", end="")
            if reflection and hasattr(agent, 'get_memory_summary'):
                # åªæ‰“å°æœ€æ–°çš„åæ€æ‘˜è¦
                print(f" | Reflection: {reflection[:80]}..." if len(str(reflection)) > 80 else f" | {reflection[:80]}")
            else:
                print()
    
    # æ±‡æ€»ç»Ÿè®¡
    total_profit = sum(hourly_profits)
    total_cost = sum(h['grid_cost'] for h in all_history)
    total_revenue = sum(h['grid_revenue'] for h in all_history)
    charge_count = sum(1 for h in all_history if h['action'] == 'CHARGE')
    discharge_count = sum(1 for h in all_history if h['action'] == 'DISCHARGE')
    hold_count = len(all_history) - charge_count - discharge_count
    
    return {
        'agent_name': agent.name,
        'total_profit': total_profit,
        'total_cost': total_cost,
        'total_revenue': total_revenue,
        'hourly_profits': hourly_profits,
        'daily_profits': daily_profits,
        'history': all_history,
        'llm_calls': getattr(agent, 'total_llm_calls', 0),
        'charge_count': charge_count,
        'discharge_count': discharge_count,
        'hold_count': hold_count,
        'final_memory': agent.get_memory_summary() if hasattr(agent, 'get_memory_summary') else None
    }


def run_experiment(
    agents: List[BaseAgent],
    df,
    num_days: int = 7,
    verbose: bool = True
) -> Dict[str, Dict]:
    """
    è¿è¡Œå®Œæ•´å®éªŒï¼Œå¯¹æ¯”å¤šä¸ª Agent
    
    Args:
        agents: Agent åˆ—è¡¨
        df: å¸‚åœºæ•°æ® DataFrame
        num_days: æ¨¡æ‹Ÿå¤©æ•°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        {agent_name: results} å­—å…¸
    """
    results = {}
    
    for agent in agents:
        print(f"\n{'='*50}")
        print(f"ğŸ¤– Running: {agent.name}")
        print('='*50)
        
        # ä¸ºæ¯ä¸ª Agent åˆ›å»ºæ–°çš„ç¯å¢ƒå®ä¾‹
        env = BatteryEnv(df)
        
        result = run_single_agent(agent, env, num_days, verbose)
        results[agent.name] = result
        
        print(f"\nâœ… {agent.name} completed: Total Profit = ${result['total_profit']:.4f}")
        if result['llm_calls'] > 0:
            print(f"   LLM API calls: {result['llm_calls']}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Battery Arbitrage Agent Experiment')
    parser.add_argument('--days', type=int, default=7, help='Number of days to simulate')
    parser.add_argument('--agents', nargs='+', default=['rule', 'reflexion'],
                        choices=['rule', 'simple_llm', 'reflexion'],
                        help='Agents to run')
    parser.add_argument('--model', type=str, default='gpt-4o-mini',
                        help='LLM model to use')
    parser.add_argument('--no-plot', action='store_true', help='Disable plotting')
    parser.add_argument('--verbose', action='store_true', default=True,
                        help='Print detailed output')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ API Key
    if 'simple_llm' in args.agents or 'reflexion' in args.agents:
        if not os.getenv('OPENAI_API_KEY'):
            print("âš ï¸  Warning: OPENAI_API_KEY not found in environment.")
            print("   Please set it in .env file or export it.")
            print("   Running only rule-based agent...\n")
            args.agents = ['rule']
    
    print("ğŸ”‹ Battery Arbitrage Agent Experiment")
    print("="*50)
    print(f"ğŸ“… Simulation period: {args.days} days")
    print(f"ğŸ¤– Agents: {', '.join(args.agents)}")
    print(f"ğŸ§  Model: {args.model}")
    print("="*50)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š Loading market data...")
    df = load_market_data()
    print(f"   Loaded {len(df)} hours of data")
    print(f"   Price range: ${df['price'].min():.2f} - ${df['price'].max():.2f}")
    
    # åˆ›å»º Agent
    agents = []
    
    if 'rule' in args.agents:
        agents.append(RuleAgent())
    
    if 'simple_llm' in args.agents:
        agents.append(SimpleLLMAgent(model_name=args.model))
    
    if 'reflexion' in args.agents:
        agents.append(ReflexionAgent(model_name=args.model))
    
    # è¿è¡Œå®éªŒ
    results = run_experiment(agents, df, num_days=args.days, verbose=args.verbose)
    
    # æ‰“å°æ‘˜è¦
    print_experiment_summary(results)
    
    # ä¿å­˜ç»“æœåˆ° CSV
    results_df = create_results_dataframe(results)
    results_df.to_csv('experiment_results.csv', index=False)
    print("ğŸ’¾ Results saved to experiment_results.csv")
    
    # ç»˜å›¾
    if not args.no_plot:
        print("\nğŸ“ˆ Generating plots...")
        
        # ç´¯ç§¯åˆ©æ¶¦å¯¹æ¯”
        hourly_results = {name: r['hourly_profits'] for name, r in results.items()}
        plot_cumulative_profits(
            hourly_results,
            title=f"Cumulative Profit Comparison ({args.days} Days)",
            save_path="cumulative_profits.png"
        )
        
        # æ¯æ—¥åˆ©æ¶¦å¯¹æ¯”
        daily_results = {name: r['daily_profits'] for name, r in results.items()}
        plot_daily_profits(
            daily_results,
            title=f"Daily Profit Comparison",
            save_path="daily_profits.png"
        )
        
        # åŠ¨ä½œåˆ†å¸ƒ
        action_results = {
            name: {
                'CHARGE': r['charge_count'],
                'DISCHARGE': r['discharge_count'],
                'HOLD': r['hold_count']
            }
            for name, r in results.items()
        }
        plot_action_distribution(
            action_results,
            title="Action Distribution by Agent",
            save_path="action_distribution.png"
        )
        
        # SOC æ›²çº¿ï¼ˆåªç”»ç¬¬ä¸€ä¸ª Agentï¼‰
        first_agent = list(results.keys())[0]
        plot_soc_profile(
            results[first_agent]['history'],
            df,
            title=f"Battery SOC Profile ({first_agent})",
            save_path=f"soc_profile_{first_agent}.png"
        )
    
    # æ‰“å° ReflexionAgent çš„æœ€ç»ˆè®°å¿†
    for name, result in results.items():
        if result.get('final_memory'):
            print(f"\nğŸ“ {name}'s Final Strategy Memory:")
            print("-" * 40)
            print(result['final_memory'])
            print("-" * 40)
    
    return results


if __name__ == "__main__":
    main()
