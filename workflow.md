# Battery Agent å®éªŒå·¥ä½œæµç¨‹ (Workflow)

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•è¿è¡Œå®Œæ•´çš„14å¤©ç”µæ± å¥—åˆ©å®éªŒï¼Œä»¥åŠå¦‚ä½•ç”Ÿæˆæ‰€æœ‰å®éªŒç»“æœå’Œå›¾è¡¨ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„æ¦‚è§ˆ

```
Battery_agent/
â”œâ”€â”€ main.py                 # ä¸»å®éªŒå…¥å£ (RuleAgent, SimpleLLM, CoT, Reflexion)
â”œâ”€â”€ main_aga.py             # AGA/MetaReflexion è®­ç»ƒè„šæœ¬
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ regenerate_results.py   # é‡æ–°ç”ŸæˆåŸºçº¿ç»“æœ (Rule, Q-Learning, DQN, Simple LLM)
â”‚   â””â”€â”€ generate_figures.py     # ç»Ÿä¸€å›¾è¡¨ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ 14days_results/         # 14å¤©å®éªŒç»“æœä¸å›¾è¡¨
â”‚   â”‚   â”œâ”€â”€ experiment_summary.json  # ç»“æ„åŒ–å®éªŒæ‘˜è¦
â”‚   â”‚   â”œâ”€â”€ profit_comparison.png
â”‚   â”‚   â”œâ”€â”€ action_distribution.png
â”‚   â”‚   â”œâ”€â”€ meta_reflexion_analysis.png
â”‚   â”‚   â”œâ”€â”€ llm_cost_efficiency.png
â”‚   â”‚   â””â”€â”€ cot_ablation_study.png
â”‚   â”œâ”€â”€ aga_training_results.json    # MetaReflexionè®­ç»ƒç»“æœ
â”‚   â”œâ”€â”€ cot_rl_experiment_results.json # CoTæ¶ˆèå®éªŒç»“æœ
â”‚   â””â”€â”€ _regen_cache_*.json          # åŸºçº¿ç¼“å­˜æ•°æ®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents.py           # æ‰€æœ‰Agentå®ç°
â”‚   â”œâ”€â”€ env.py              # ç”µæ± ç¯å¢ƒ
â”‚   â””â”€â”€ rl_baselines.py     # RLåŸºçº¿ (Q-Learning, DQN, MPC)
â””â”€â”€ data/
    â””â”€â”€ caiso_enhanced_data.csv  # CAISOå¸‚åœºæ•°æ®
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šè¿è¡Œå…¨éƒ¨å®éªŒ

### ä¸€é”®è¿è¡Œæ‰€æœ‰å®éªŒå¹¶ç”Ÿæˆå›¾è¡¨

```bash
# 1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# 2. è¿è¡Œå®Œæ•´å®éªŒæµç¨‹
./run_all_experiments.sh
```

æˆ–è€…æŒ‰æ­¥éª¤æ‰‹åŠ¨è¿è¡Œï¼š

---

## ğŸ“Š åˆ†æ­¥è¿è¡ŒæŒ‡å—

### Step 1: è¿è¡ŒåŸºçº¿å®éªŒ (Rule-Based, Q-Learning, DQN, Simple LLM)

```bash
python scripts/regenerate_results.py --methods rule-based q-learning dqn simple_llm --days 14
```

**è¾“å‡ºæ–‡ä»¶:**
- `outputs/_regen_cache_rule-based.json`
- `outputs/_regen_cache_q-learning.json`
- `outputs/_regen_cache_dqn.json`
- `outputs/_regen_cache_simple_llm.json`
- `outputs/full_experiment_results_14days.csv`

**é¢„è®¡è€—æ—¶:** ~5åˆ†é’Ÿ (RLè®­ç»ƒ) + ~10åˆ†é’Ÿ (Simple LLM 336æ¬¡APIè°ƒç”¨)

---

### Step 2: è¿è¡Œ MetaReflexion (AGA) è®­ç»ƒ

```bash
python main_aga.py --days 14 --verbose
```

**è¾“å‡ºæ–‡ä»¶:**
- `outputs/aga_training_results.json` - è®­ç»ƒè¿‡ç¨‹æ•°æ®
- `outputs/best_strategy_*.py` - æœ€ä½³ç”Ÿæˆç­–ç•¥ä»£ç 

**é¢„è®¡è€—æ—¶:** ~3åˆ†é’Ÿ (çº¦15æ¬¡LLMè°ƒç”¨)

**å…³é”®æŒ‡æ ‡:**
- æ€»åˆ©æ¶¦: ~$42.35
- LLMè°ƒç”¨: 15æ¬¡
- ç”Ÿæˆç­–ç•¥æ•°: 14ä¸ª
- Pass@1: 100%

---

### Step 3: è¿è¡Œ CoT æ¶ˆèå®éªŒ

```bash
python -c "
from src.experiment import run_cot_ablation_study
results = run_cot_ablation_study(num_days=14)
import json
with open('outputs/cot_rl_experiment_results.json', 'w') as f:
    json.dump(results, f, indent=2)
print('CoT ablation study completed!')
"
```

**è¾“å‡ºæ–‡ä»¶:**
- `outputs/cot_rl_experiment_results.json`

**æ¶ˆèå˜ä½“:**
| æ¨¡å‹ | æè¿° | é¢„æœŸåˆ©æ¶¦ |
|------|------|----------|
| Model A (Full) | å®Œæ•´CoT + æ¨ç†å¥–åŠ± | ~$17.32 |
| Model B (No Reward) | CoTä½†æ— æ¨ç†å¥–åŠ± | ~$12.44 |
| Model C (No CoT) | æ— CoTç›´æ¥è¾“å‡º | ~-$3.94 |

**é¢„è®¡è€—æ—¶:** ~30åˆ†é’Ÿ (çº¦1000æ¬¡LLMè°ƒç”¨)

---

### Step 4: ç”Ÿæˆæ‰€æœ‰å®éªŒå›¾è¡¨

```bash
python scripts/generate_figures.py
```

**è¾“å‡ºæ–‡ä»¶ (ä½äº `outputs/14days_results/`):**

| æ–‡ä»¶å | å†…å®¹æè¿° |
|--------|----------|
| `profit_comparison.png` | 14å¤©æ€»åˆ©æ¶¦æ’å + ç´¯ç§¯åˆ©æ¶¦æ›²çº¿ |
| `action_distribution.png` | å„æ–¹æ³•Actionåˆ†å¸ƒå¯¹æ¯” (æ¨ªå‘å †å æŸ±çŠ¶å›¾) |
| `meta_reflexion_analysis.png` | AGAåˆ†æ: Pass@1 + ä»£ç æ¼”è¿› + é˜¶æ¢¯æ›²çº¿ |
| `llm_cost_efficiency.png` | LLMæˆæœ¬æ•ˆç‡å¯¹æ¯” |
| `cot_ablation_study.png` | CoTæ¶ˆèå®éªŒ + é˜ˆå€¼å­¦ä¹ æ›²çº¿ |

---

## ğŸ“ˆ å®éªŒç»“æœæ‘˜è¦ (14å¤©)

### åˆ©æ¶¦æ’å

| æ’å | æ–¹æ³• | æ€»åˆ©æ¶¦ | LLMè°ƒç”¨ | æ•ˆç‡ ($/call) |
|:----:|------|-------:|--------:|--------------:|
| ğŸ¥‡ | MetaReflexion (AGA) | $42.35 | 15 | $2.82 |
| ğŸ¥ˆ | Rule-Based | $34.23 | 0 | - |
| ğŸ¥‰ | Q-Learning | $31.50 | 0 | - |
| 4 | CoT (Full) | $17.32 | 350 | $0.05 |
| 5 | DQN | $13.19 | 0 | - |
| 6 | CoT (No Reward) | $12.44 | 350 | $0.04 |
| 7 | Simple LLM | $5.36 | 336 | $0.02 |

### å…³é”®å‘ç°

1. **MetaReflexion (AGA)** ä»¥æœ€å°‘çš„LLMè°ƒç”¨å®ç°æœ€é«˜åˆ©æ¶¦
   - ç”Ÿæˆå¯æ‰§è¡ŒPythonä»£ç  (Pass@1=100%)
   - é˜¶æ¢¯å¼å­¦ä¹ æ›²çº¿ï¼šæ¯å‘ç°æ–°é€»è¾‘åˆ©æ¶¦è·³å‡

2. **CoTæ˜¯LLM Agentçš„å…³é”®**
   - æ— CoT (Model C): è´Ÿåˆ©æ¶¦ (-$3.94)
   - æœ‰CoT (Model A): æ­£åˆ©æ¶¦ ($17.32)
   - æå‡: **5.4x**

3. **Simple LLM çš„"ç›²ç›®"è¡Œä¸º**
   - 98% HOLDåŠ¨ä½œ
   - æ— æ³•è¿›è¡Œæœ‰æ„ä¹‰çš„äº¤æ˜“å†³ç­–

---

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒé…ç½® (`configs/default.yaml`)

```yaml
battery:
  capacity_kwh: 13.5
  max_charge_kw: 5.0
  max_discharge_kw: 5.0
  roundtrip_efficiency: 0.9
  min_soc: 0.1
  max_soc: 0.95

experiment:
  days: 14
  initial_soc: 0.5
  seed: 42
```

### APIé…ç½® (`.env`)

```bash
OPENAI_API_KEY=your_api_key
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_MODEL=gpt-4
```

---

## ğŸ§¹ æ¸…ç†ä¸é‡ç½®

```bash
# æ¸…ç†æ‰€æœ‰ç¼“å­˜å’Œè¾“å‡º
rm -rf outputs/_regen_cache_*.json
rm -rf outputs/14days_results/*.png
rm -rf outputs/*.json

# é‡æ–°è¿è¡Œå…¨éƒ¨å®éªŒ
python scripts/regenerate_results.py --force
python main_aga.py --days 14
python scripts/generate_figures.py
```

---

## ğŸ“ å®Œæ•´è¿è¡Œè„šæœ¬

åˆ›å»º `run_all_experiments.sh`:

```bash
#!/bin/bash
set -e

echo "=========================================="
echo "Battery Agent - Full Experiment Pipeline"
echo "=========================================="

# Step 1: åŸºçº¿å®éªŒ
echo -e "\n[1/4] Running baseline experiments..."
python scripts/regenerate_results.py --methods rule-based q-learning dqn simple_llm --days 14

# Step 2: MetaReflexion
echo -e "\n[2/4] Running MetaReflexion (AGA)..."
python main_aga.py --days 14

# Step 3: CoTæ¶ˆèå®éªŒ (å¯é€‰ï¼Œè€—æ—¶è¾ƒé•¿)
# echo -e "\n[3/4] Running CoT ablation study..."
# python -c "from src.experiment import run_cot_ablation_study; ..."

# Step 4: ç”Ÿæˆå›¾è¡¨
echo -e "\n[4/4] Generating figures..."
python scripts/generate_figures.py

echo -e "\n=========================================="
echo "All experiments completed!"
echo "Results: outputs/14days_results/"
echo "=========================================="
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

- AGENTÂ² Paper: Agent-Generates-Agent architecture
- Reflexion: Language Agents with Verbal Reinforcement Learning
- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

---

*æœ€åæ›´æ–°: 2026-01-09*
